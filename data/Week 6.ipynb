{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Make the kind of data you want to see in the world \n",
    "\n",
    "Welcome back! \n",
    "\n",
    "Last week we took a look at importing data into a Pands `DataFrame`, using Pathlib's `Path` objects. We also introduced you to the structure of a`DataFrame` through `class methods` like `.head()`, `.tail()` (which display the top or bottom of your `df` respectively) and `attributes` like the `shape` of the `DataFrame`, the `df.columns`, and the `df.index`. \n",
    "\n",
    "This week we're going to look at some options for cleaning a dataset, such as `dropping` unneeded columns and `rows`, standardising or `renaming` columns, as well as some other cool things (like ) `slicing` your data, and 'fixing' inconsistent data. \n",
    "\n",
    "Before we get into that though, we need to import some data to work with so this is a good time to practice what you learned last week. In the cell below:\n",
    "\n",
    " 1. import pandas and pathlib (don't forget the 'as' bit)\n",
    " 2. create a Path() to either the .csv or .sav version of your data (s'up to you, you should have fixed the issue with importing SPSS files last week)\n",
    " 3. use that Path() to import your data into a DataFrame (make sure you assign it to a variable, and remember the we often use the shorthand 'df' when doing so)\n",
    " 4. make sure that your data has imported correctly by calling displaying the head of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're on a windows device don't forget the 'r-string'\n",
    "# Import the modules you need first\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, now you have some data to work with. We also need some example data, so make sure to run the cell below to make the `bands_df` that we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise some list objects that contains our data, this could also be a list of lists, or a dict of lists for example\n",
    "\n",
    "names = ['John Lennon', 'Morris Day', 'Robert Rtujillo', 'Prince', 'Pete Best', 'Frank Zappa']\n",
    "bands = ['Beatles', 'The Time', 'metalica', 'The Time', 'Beatles', 'The Mothers']\n",
    "instruments = ['Guitar', 'Vocals', 'Bass', 'Multi', 'Drums', 'Multi']\n",
    "writer = ['yes', 'no', 'no', 'yes', 'no', 'yes']\n",
    "orig = ['yes', 'yes', 'no', 'yes', 'yes', 'yes']\n",
    "score1 = [10, 5, 3, 6, 8, 2]\n",
    "score2 = [1, 4, 3, 7, 4, 2]\n",
    "\n",
    "bands_df = pd.DataFrame(# opening brackets but moving to new line for readability, note the uppercase D and F in the call\n",
    "    list(zip(names,bands, instruments, writer, orig, score1, score2 )), #first argument note the comma at the end of it, this is a couple of nested functions\n",
    "    columns = ['Participant name', 'band', 'instrument', 'song writer', 'original member', 'score1', 'score2' ]# second argument , passing a list to the columns arguments\n",
    "    )# closing the first pair of brackets to complete the function call"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
